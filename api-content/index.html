{"posts":[{"title":"Docker镜像架构不一致怎么办","content":"当镜像的架构与服务器架构不一致时，可以采用将正常运行的容器打包成新镜像的方法 Docker buildx 构建多架构镜像 详见这里 docker buildx build --platform linux/arm64 -t discuz/test-for-buildx . --load 开启 binfmt_misc 来运行非本地架构 Docker 镜像 详见这里 启用 binfmt_misc ：运行一个特权容器，容器里面写好了设置脚本 使用Docker镜像安装模拟器： tonistiigi/binfmt docker run --privileged --rm tonistiigi/binfmt --install all Linux kernel &gt;= 4.8: 自该Linux内核版本 binfmt_misc 支持 fix-binary (F) flag。fix_binary 标志允许内核在容器或chroot内使用binfmt_misc注册的二进制格式处理程序，即使该处理程序二进制文件不是该容器或chroot内可见的文件系统的一部分。 binfmt_misc file system mounted: 需要挂载binfmt_misc文件系统，以便用户空间工具可以控制此内核功能，即注册和启用处理程序。 配置 binfmt_misc QEMU 是一个很棒的开源项目，它可以模拟很多平台。将 QEMU 和 Docker 结合起来使用能使得我们更容易的构建跨平台的容器镜像。集成 QEMU依赖于 Linux 内核功能 。Linux 内核中的 binfmt_misc功能可以使得内核识别任意类型的可以执行文件格式，并传递到特定的用户空间应用程序和虚拟机（https://zh.wikipedia.org/wiki/Binfmt_misc）。当 Linux 遇到一种无法识别的可执行文件格式（比如说其它平台的可执行文件格式）时，它会检查有没有配置任何“用户空间应用程序”用于处理它。如果检测到了，就将可执行文件传递给该应用程序。 为此，我们需要在内核当中注册其它平台的可执行文件格式。 对于使用 Docker Desktop（MacOS 和 Windows 上都是）的同学，因为默认配置了 binfmt_misc，可以跳过这一步。而使用 Linux 发行版操作系统的同学则需要自行安装配置 binfmt_misc，以便能够非原生的其它平台的镜像。 要在宿主机上执行其它 CPU 平台的指令，需要安装 QEMU 模拟器。因为程序执行时会在当前程序可见的文件系统中查找动态库，而在容器或chroot环境中注册的处理程序在其它的 cgroup namespace 中可能无法找到，所以需要静态编译连接的QEMU。同时，我们需要安装一个包含足够新的update-binfmts二进制文件的包，以便能够支持fix-binary（F）标志，并在注册QEMU模拟器时实际使用，这样才能结合 buildx 一起镜像跨平台构建。 QEMU 和 binfmt_misc 支持工具可以通过宿主机或者Docker 容器镜像安装。但是，使用Docker镜像安装配置能让事情变得更加简单。镜像 docker/binfmt 中包含QEMU二进制文件和在binfmt_misc中注册QEMU的安装脚本。 docker run --privileged docker/binfmt:66f9012c56a8316f9244ffd7622d7c21c1f6f28d 执行完后，我们验证下是否注册成功了。成功注册后，/proc/sys/fs/binfmt_misc 目录中会有多个qemu-前缀的文件。查看 /proc/sys/fs/binfmt_misc/qemu-aarch64 文件内容，可以看到 falgs 标志为 OCF，说明这个处理程序是通过 （F）标志注册的，能够正常的结合 buildx 完成跨平台构建。 多平台容器镜像构建就看这一篇 容器镜像多架构支持介绍 docker官网中多平台镜像的内容 👇 Docker Desktop提供了binfmt_misc多架构支持，这意味着您可以为不同的Linux架构(如arm、mips、ppc64le，甚至s390x)运行容器。 这并不需要容器本身的任何特殊配置，因为它使用了来自Docker for Mac VM的qemu-static。因此，您可以运行ARM容器，例如busybox映像的arm32v7或ppc64le变体。 ","link":"https://dove-gugugu.github.io/post/docker-jing-xiang-jia-gou-bu-yi-zhi-zen-me-ban/"},{"title":"MySQL主从复制的配置步骤","content":"一、准备工作 确保主库和从库服务器之间网络连接正常。 主库和从库的 MySQL 版本保持一致或者相近，建议主库版本高于或等于从库版本。 在主库和从库上分别创建用于复制的用户，并设置该用户具有复制所需的权限。 主库和从库上的文件系统最好相同，例如都使用 InnoDB 存储引擎。 二、配置主库db1 修改主库的 /etc/my.cnf 文件，在[mysqld]段添加以下配置： [mysqld] # 开启 binary log log-bin = mysql-bin # 记录 slave 的信息 server-id = 1 # 指定中继日志文件的名称 relay-log = mysql-relay-bin replicate-wild-ignore-table=mysql.% replicate-wild-ignore-table=test.% replicate-wild-ignore-table=information_schema.% 其中： replicate-wild-ignore-table用于在复制过程中忽略特定的表。这里使用了通配符%。这意味着任何以mysql.、test.、information_schema.开头的表都不会被复制到从库 重启主库服务 sudo service mysql restart 三、配置从库 在从库的 my.cnf 文件中添加如下配置： [mysqld] # 设置 server-id server-id = 2 # 指定二进制日志文件的名称 log_bin = mysql-bin log_slave_updates = 1 # 从库设置为只读 read_only = 1 # 指定中继日志文件的名称 relay-log = mysql-relay-bin replicate-wild-ignore-table=mysql.% replicate-wild-ignore-table=test.% replicate-wild-ignore-table=information_schema.% 其中: log_slave_updates = 1表示从服务器在应用主服务器复制过来的更新时，也会将这些更新记录到自己的二进制日志中 重启从库服务 sudo service mysql restart 四、复制用户并授权 db1创建复制用户: GRANT REPLICATION SLAVE ON *.* TO 'repl_user'@'192.168.88.%' IDENTIFIED BY 'repl_passwd'; 在主服务器db1上创建了一个名为repl_user的用户，并且授予了这个用户作为从服务器进行数据复制的权限。这个用户可以连接到任何以192.168.88开头的IP地址，并且密码是repl_passwd。ON *.*表示这个用户对所有数据库和表都有复制权限。 查看主服务器状态: SHOW MASTER STATUS; 显示主服务器的二进制日志文件的状态信息。它会返回当前的二进制日志文件名和日志文件中的下一个可获取的位置（偏移量） db2设置db1为主服务器： CHANGE MASTER TO master_host='192.168.88.11', master_user='repl_user', master_password='repl_passwd', master_log_file='mysql-bin.000001', master_log_pos=120; master_host: 主服务器的IP地址或主机名。 master_user: 在主服务器上创建的复制用户的用户名。 master_password: 复制用户的密码。 master_log_file: 主服务器的二进制日志文件名，这个文件名是从SHOW MASTER STATUS;命令中获取的。 master_log_pos: 二进制日志文件中的偏移量，从这个位置开始复制数据，这个偏移量也是从SHOW MASTER STATUS;命令中获取的。 启动从服务器复制: START SLAVE; 启动从服务器的复制进程。一旦执行，从服务器将开始连接到主服务器，请求数据，并开始复制主服务器上的数据更改。 五、验证复制是否成功 检查主从复制状态： 在主库上执行以下命令：mysql -u root -p -e &quot;SHOW MASTER STATUS;&quot; 记下显示的File和Position值。 在从库上验证复制状态： 在从库上执行以下命令：mysql -u root -p -e &quot;SHOW SLAVE STATUS\\G&quot; 确认Master_Log_File和Read_Master_Log_Pos的值与步骤5中的主库状态一致，同时确保Slave_IO_Running和Slave_SQL_Running的值为Yes。 ","link":"https://dove-gugugu.github.io/post/mysql-zhu-cong-fu-zhi-de-pei-zhi-bu-zou/"},{"title":"Go多种安装","content":"记录下在不同环境下搭建和配置Go语言的开发环境：1. 在Ubuntu上安装Go语言环境，并使用VSCode远程连接进行开发。2. 在本地直接安装Go，以及安装和管理多个Go版本。3. 使用Docker来创建Go开发环境，以保持系统环境的纯净和开发环境的一致性。 Ubuntu安装Go环境后使用VSCode远程连接开发 服务器安装Go 官网下载安装包，解压到 /usr/local，检查该路径下是否出现go 在 /etc/profile 新增配置 export PATH=$PATH:/usr/local/src/go/bin 或在 /home/{user}/.profile 中配置 使profile配置立即生效 source /home/{user}/.profile 如果在 /etc/profile 修改的需要重启 大概率需要配置镜像代理，不然下载依赖太慢 go env -w GOPROXY=https://goproxy.cn,direct VSCode远程连接服务器 安装 Remote-SSH 插件，用以远程连接服务器 使用 Remote-SSH 连接远程服务器后 给服务器安装 Go 插件 打开命令行输入 Go: Install/Update 什么的，之后全选安装 本地安装Go开发环境 打开官网下载后直接安装即可，现在的版本不需要配置PATH确实方便了些。 安装只需要选择下安装目录，安装好后打开命令行看下已经安装成功了 安装多个Go版本 我们可以在同一台计算机上安装多个Go版本。安装的版本可以前往官网的版本列表来查看。 这里翻译下官网的操作： 注意：要使用这里描述的方法安装，需要安装git。 要安装其他Go版本，请运行go install命令，指定要安装的版本的下载位置。下面的示例使用版本1.10.7进行说明： $ go install golang.org/dl/go1.10.7@latest $ go1.10.7 download 要使用新下载的版本运行go命令，请将版本号附加到go命令，如下所示： $ go1.10.7 version go version go1.10.7 linux/amd64 当您安装了多个版本时，您可以发现每个版本的安装位置，查看版本的GOROOT值。例如，运行如下命令： $ go1.10.7 env GOROOT 要卸载下载的版本，只需删除由其GOROOT环境变量和goX.Y.Z二进制文件指定的目录。 Docker部署Go开发环境 详见：使用 Docker 一步一步搭建 Go 语言开发环境 发现有大佬 docker 来实现Go开发环境的搭建，十分厉害，这里简单记录下。 自定义 Go Shell 脚本来执行 go #!/bin/bash ​ docker run --rm -it \\ -u $UID:$UID \\ -e XDG_CACHE_HOME=/tmp/.cache \\ -e GOPROXY=https://goproxy.cn \\ -v $PWD:/srv/app \\ -v $HOME/go:/go \\ -w /srv/app \\ -p 8080:8080 \\ golang:alpine go $@ -it 参数使运行的容器可以接受交互操作，所以按 Ctrl + c 就可以终止程序了 -u 参数指定了当前用户 ID。使初始化 go.mod 的权限为当前用户而非 root 权限 -e Docker 用来设置容器运行时的环境变量 GOPROXY给Go提供镜像加速功能 XDG_CACHE_HOME防止缓存用途的目录因为权限问题创建失败 -v Docker 挂载目录的参数 $PWD 代表当前执行命令的位置，/srv/app 是镜像容器中的目录。 映射目录 -v $HOME/go:/go，这是因为 go mod 会把软件包安装到 $GOPATH 定义的位置，这个位置如果不映射到容器外的目录，每次执行结束都会跟随容器一起销毁，所以每次都会要重新项目依赖的安装软件包。 -w Docker 设置容器运行时的工作主目录。这主要是为了配合上面的 -v 参数来执行当前目录下的 go 代码 自定义编辑脚本 上面自定义的 go Shell 脚本虽然也能执行 build 命令，但我发现编译后的执行文件无法在容器外执行。因为上面的自定义脚本使用的是 alpine 标签的 go 语言 Docker 镜像。要解决这个问题有两个方案： 采用和但前开发系统一致的 Docker 镜像。 使用 Go 语言的交叉编译功能。 使用交叉编译功能可参考以下脚本： #!/bin/bash ​ docker run --rm -it \\ -u $UID:$UID \\ -e XDG_CACHE_HOME=/tmp/.cache \\ -e GOPROXY=https://goproxy.cn \\ -e CGO_ENABLED=0 \\ -e GOOS=linux \\ -e GOARCH=amd64 \\ -v $PWD:/srv/app \\ -v ~/Services/go:/go \\ -w /srv/app \\ golang:alpine go build $@ 该脚本添加了 CGO_ENABLED，GOOS，GOARCH 这三个交叉编译环境变量。并添加了 build 参数 ","link":"https://dove-gugugu.github.io/post/go-duo-chong-an-zhuang/"},{"title":"MySQL基础调优","content":"参加MySQL技能强化训练营做的笔记，从硬件优化到MySQL调优，实现从BIOS设置、SSD存储、文件系统选择，到内核参数和数据库配置的基础优化 硬件层相关优化 内存方面 修改BIOS设置中的Memory Frequency，选择Maximum Performance 在内存设置菜单中，启用Node Interleaving，避免NUMA（非统一内存访问）问题 执行numactl --hardware可以查看硬件对 NUMA 的支持信息： 执行numactl --show显示当前的 NUMA 设置： 升级内存容量，没有什么是加内存不能解决的 磁盘存储方面 建议使用SSD磁盘 磁盘RAID级别尽量选择RAID 10，而不是RAID 5。RAID 10虽然性能优异，但牺牲了存储空间。如果存储需求较大，可以考虑使用RAID 6或RAID 50，它们在提供冗余的同时，存储效率更高。 补充说明[1] RAID0：数据被分成从512字节到数兆字节的若干块后，再交替写到磁盘中。第1块被写到磁盘1中，第2块被写到磁盘2中，如此类推。当系统到达阵列中的最后一个磁盘时，就写到磁盘1的下一分段。将I/O负载平均分配到所有的驱动器中。由于驱动器可以同时写或读，使得性能显著提高。理论I/O速度相当于单盘的N倍。 RAID1：可以由软件或硬件方式实现。所有数据都被写入两个独立的物理磁盘。磁盘本质上是彼此的镜像。如果一个磁盘出现故障，可以使用另一个磁盘来检索数据。读快写慢。 RAID5：数据的奇偶校验信息存储到除自身以外的其他每一块硬盘设备上，没有备份硬盘中的真实数据信息。当硬盘设备出现问题后通过奇偶校验信息来尝试重建损坏的数据，这样的技术特性“妥协”地兼顾了硬盘设备的读写速度、数据安全性与存储成本问题。 RAID6：引入双重校验的概念，它可以保护阵列中同时出现两个磁盘失效时，阵列仍能够继续工作，不会发生数据丢失。它的成本要高于 RAID5 许多，因此， RAID6 很少得到实际应用，主要用于对数据安全等级要求非常高的场合。它一般是替代 RAID10 方案的经济性选择。 RAID10：也就是RAID0+1，使用磁盘镜像和条带化的组合。数据通常先镜像，然后条带化。如果在一个条带组中丢失驱动器，则必须从另一个条带组中访问数据，因为条带组没有奇偶性。RAID 1+0至少需要4个物理磁盘。 比较项 RAID 0 RAID 1 RAID 5 RAID 6 RAID 10 机制 数据分块、数据条带化，分布在阵列的各个驱动器上。 数据分别写入数据盘和镜像盘，存储两次。 数据是条带的，奇偶校验数据分布在所有驱动器上。 块级条带和双分布式奇偶校验，冗余信息重复。 数据同时镜像和分条。 硬盘数 2以上 2以上偶数 3到16个 4个以上 4以上 容错 没有 单驱动失败 单驱动失败 两个驱动器故障 每个子阵列最多有1个硬盘故障 读性能 高 媒介 低 低 高 写性能 高 媒介 低 低 媒介 利用率 100% 50% 67% - 94% 50% - 88% (N-2)/N 50% 典型应用 高端工作站，数据记录，实时渲染，非常短暂的数据。 操作系统，事务数据库，可用于关键存储和小型服务器。 数据仓库，网络服务，归档 数据归档、备份到磁盘、高可用性解决方案、大容量服务器 快速数据库，文件服务器，应用服务器 文件系统层面 使用deadlineI/O调度器，使用deadlineI/O调度器可以减少I/O操作的延迟，尽量不要用cfq 不要使用ext3，使用xfs文件系统。增加noatime, nodiratime, nobarrier这几个选项禁止记录文件或目录最近一次访问时间戳 上述三者I/O调度器（I/O Scheduler）的区别： CFQ (Completely Fair Queueing): 原理：CFQ调度器是一种基于完全公平队列的调度算法，它旨在为所有运行中的进程提供公平的服务。CFQ通过为每个进程创建一个独立的队列来实现这一点，从而确保每个进程都能获得相等的磁盘访问时间。 特点：CFQ适合于多用户环境或有大量并发I/O操作的场景，因为它可以提供较好的公平性。但这种调度器在处理单个进程的大量I/O请求时会尝试在所有进程之间平均分配磁盘时间，这可能导致单个进程的I/O延迟增加。 Deadline: 原理：deadline调度器通过设置一个截止时间（deadline）来确保每个I/O请求都能在特定的时间内得到服务。它维护了两个队列：一个用于处理请求的当前队列，另一个用于存放超出截止时间的请求。 特点：deadline调度器特别适合于需要低延迟的实时应用，因为它可以保证I/O请求不会无限期地等待。通过设置截止时间，可以减少I/O操作的延迟，特别是在有实时性要求的场景中。 Noop (No Operation): 原理：noop调度器是一种非常简单的调度器，它按照I/O请求到达的顺序来处理它们，即先进先出（FIFO）。 特点：noop调度器的性能通常不如deadline或cfq，因为它没有进行任何优化来减少延迟或提供公平性。但在某些特定的工作负载下，如顺序读写操作，noop可能会表现得更好，因为它避免了额外的调度开销。 linux内核参数方面 可修改vm.swappiness，降低swap使用率 参数值大小对如何使用swap分区有很大联系。值越大表示越倾向于使用swap，越小表示越积极使用物理内存。默认值为60，表示内存使用率超过100-60=40%时开始使用交换分区 将vm.dirty_background_ratio设置为5-10，将vm.dirty_ratio设置为它的两倍左右，以确保能持续将脏数据刷新到磁盘，避免瞬间I/O写，产生严重等待 vm.dirty_background_ratio 是内存可以填充脏数据的百分比 vm.dirty_ratio是可以用脏数据填充的绝对最大系统内存量 可以考虑调整kernel.shmall和kernel.shmmax参数，以优化共享内存的使用，这对于某些内存密集型应用很有帮助 kernel.shmall参数表示系统任意时刻可以分配的所有共享内存段的总和的最大值 kernel.shmmax该参数定义了共享内存段的最大尺寸（以字节为单位） Mysql参数优化 innodb_buffer_pool_size设置为物理内存的20%-65%左右 通过innodb_log_file_size来调节Redo log的空间，避免太大增加MySQL恢复的时间 skip_name_resolve：生产上建议开启成1，这样mysql server不会对客户端连接使用反向dns解析，否则经常会出现客户端连上后有timeout现象，如果设成了1带来的问题就是你不能在mysql中使用主机名来对客户端权限进行划分，而是需要使用ip 配置的innodb_buffer_pool_size是否合适 可以通过分析InnoDB缓冲池的性能来验证当前的innodb_buffer_pool_size是否合适。 可以使用以下公式计算InnoDB缓冲池性能： Performance = innodb_buffer_pool_reads / innodb_buffer_pool_read_requests * 100 innodb_buffer_pool_reads：表示InnoDB缓冲池无法满足的请求数。需要从磁盘中读取。 innodb_buffer_pool_read_requests：表示从内存中读取逻辑的请求数。 例如，用docker临时新建一个MySQL，检查当前InnoDB缓冲池的性能 show status like 'innodb_buffer_pool_read%'; 计算未命中率：Innodb_buffer_pool_readsInnodb_buffer_pool_read_requests×100%计算未命中率： \\frac{\\text{Innodb\\_buffer\\_pool\\_reads}}{\\text{Innodb\\_buffer\\_pool\\_read\\_requests}} \\times 100\\% 计算未命中率：Innodb_buffer_pool_read_requestsInnodb_buffer_pool_reads​×100% 即 1020 / 15602 * 100% = 6.5376233816177413152159979489809% 这个未命中率告诉我们有多少比例的读请求没有直接从缓冲池中找到所需的数据页，而不得不从磁盘中读取。这里意味着InnoDB可以满足缓冲池本身的大部分请求。从磁盘完成读取的百分比非常小。因此无需增加innodb_buffer_pool_size值。 InnoDB buffer pool 命中率： innodb_buffer_pool_read_requestsinnodb_buffer_pool_read_requests+innodb_buffer_pool_reads×100%\\frac{\\text{innodb\\_buffer\\_pool\\_read\\_requests}}{\\text{innodb\\_buffer\\_pool\\_read\\_requests} + \\text{innodb\\_buffer\\_pool\\_reads}} \\times 100\\% innodb_buffer_pool_read_requests+innodb_buffer_pool_readsinnodb_buffer_pool_read_requests​×100% 此值低于99%，则可以考虑增加innodb_buffer_pool_size。 超详细各种RAID详细对比，补齐盲区 ↩︎ ","link":"https://dove-gugugu.github.io/post/mysql-ji-chu-diao-you/"},{"title":"Gridea自定义主题组件","content":"本博客是使用 Gridea + GitHub Pages 搭建起来的，但是 Gridea 自带的主题比较少，所以萌生了自己小改一下当前主题的想法，给当前主题添加些小组件并使用云函数防止私有Key泄露。 文件结构 首先是简单了解下主题的文件结构，Gridea 的主题都在 /themes 文件夹中，该目录下每个文件夹都是一个主题，以自带的 fly 主题为例，文件结构为： fly - 主题文件夹名称 (建议用小写，中划线分隔) ├── assets - 资源文件夹（必须，不可更名） │ ├── media - 主题静态资源存放目录（可选，不可更名） │ │ └── fonts - 字体图标文件夹（示例） │ │ │ ├── icomoon.ttf │ │ │ └── icomoon.woff │ │ └── images - 主题用图片文件（示例） │ └── styles - 样式文件夹（必须，不可更名） │ ├── _blocks - 样式模块文件夹（可选，可自定义命名） │ │ ├── footer.less │ │ ├── header.less │ │ └── tag.less │ ├── _core - 样式模块文件夹（可选，可自定义命名） │ │ ├── base.less │ │ ├── colors.less │ └── main.less - 主样式文件 (必须，不可更名) └── templates - 页面模版文件夹（必须，不可更名） │ ├── _blocks - 页面模版文件夹（可选，可自定义命名） │ │ ├── footer.ejs │ │ ├── head.ejs │ │ ├── header.ejs │ ├── index.ejs - 主页，列表页 (必须，不可更名) │ ├── post.ejs - 文章页 (必须，不可更名) │ ├── archives.ejs - 归档页 (必须，不可更名) │ ├── tags.ejs - 标签列表页 (必须，不可更名) │ ├── tag.ejs - 标签详情页 (必须，不可更名) │ └── friends.ejs - 自定义模版 (可选，任意命名) └── config.json - 主题配置文件 (可选，推荐) └── style-override.js - 主题样式自定义文件 (可选) 其中值得注意的是，页面主题都是由 ejs 模板引擎生成的，样式文件也是 less 格式，统一由 Gridea 根据模板文件生成静态文件同步到 Github 上，Github Pages 展示页面。 给当前主题添加一言 一言api接口 一言主站 一言是个很优秀的短句api，每次调用都会随机返回一个句子，可以给博客增色不少。 根据一言的文档我们可以根据需求得到下列api接口： https://v1.hitokoto.cn/?c=d&amp;c=i&amp;encode=text 其中，参数c为句子类型，d和i表示返回的类型为文学和诗词；encode为返回编码，text表示返回纯洁文本 修改模板 以simple主题为例，原模板是静态的固定文字，我们需要调用一言接口来实现动态的展示文字，故而需要写个简单的js来修改div.site-description的内容。 我们可以直接在scripts.ejs中新增一段js来调用一言接口 &lt;script&gt; // 获取一言api数据并更新description div标签的文本内容和meta标签的content内容 fetch('https://v1.hitokoto.cn/?c=d&amp;c=i&amp;encode=text') .then(response =&gt; response.text()) .then(data =&gt; { // 更新description div标签的文本内容 document.getElementsByClassName('site-description')[0].innerText = data; // 更新meta标签的content内容 document.querySelector('meta[name=description]').setAttribute('content', data); }) .catch(error =&gt; { console.error('访问一言api发生错误:', error); }); &lt;/script&gt; 这样就搞定了，记得同步到GitHub上哦。 添加实时天气组件 现在来点更有意思的，根据当前访问的ip地址来显示该ip地址所在地区的实时天气。大体思路为调用高德Web服务API来实现ip定位和天气查询，然后使用华为云函数来访问上述接口以此保护私有Key不在前端泄露，最后博客直接调用封装好的云函数来实现。 调用高德API 首先是采用高德地图提供的接口来实现ip定位和天气查询。调用高德家的接口需要注册个开发者账号来获取到自己的Key，获取到Key之后可以开始调用接口来实现具体代码逻辑了。 服务类型 URL 请求方式 IP定位API https://restapi.amap.com/v3/ip?parameters GET 天气查询API https://restapi.amap.com/v3/weather/weatherInfo?parameters GET IP定位的接口可以不写ip参数，根据当前访问的ip来反显地址。而且返回的adcode可以直接给天气查询接口使用，比较方便。 但是实际测试时发现有个问题，如下图所示，广州市的adcode返回的是440000，是广东省的编码，深圳返回正常的编码440300，这就影响了之后调用天气接口返回的信息了（天气可能有点差别，返回的地市区信息也会只显示为省份） 所以在实际调用代码中，我又调用了下行政区域查询接口： URL 请求方式 https://restapi.amap.com/v3/config/district?parameters GET 简易代码如下： try { let ipUrl = 'https://restapi.amap.com/v3/ip?ip=' + clientIp + '&amp;key=&lt;我的Key&gt;'; const ipResponse = await fetch(ipUrl); if (!ipResponse.ok) { throw new Error('Failed to fetch IP location'); } const ipData = await ipResponse.json(); if (ipData.status === '1') { let adcode = ipData.adcode; let city = ipData.city; const addUrl = `https://restapi.amap.com/v3/config/district?keywords=${city}&amp;subdistrict=0&amp;key=&lt;我的Key&gt;`; const addResponse = await fetch(addUrl); if (!addResponse.ok) { throw new Error(`Network response was not ok: ${addResponse.status}`); } const addData = await addResponse.json(); // 检查districts是否为空 if (addData.districts.length &gt; 0) { // 获取第一个district的adcode adcode = addData.districts[0].adcode; } const weatherResponse = await fetch(`https://restapi.amap.com/v3/weather/weatherInfo?city=${adcode}&amp;key=&lt;我的Key&gt;`); if (!weatherResponse.ok) { throw new Error('Failed to fetch weather information.'); } const weatherData = await weatherResponse.json(); if (weatherData.status === '1' &amp;&amp; weatherData.lives.length &gt; 0) { const liveWeather = weatherData.lives[0]; res.writeHead(200, { 'Content-Type': 'application/json' }); res.end(JSON.stringify(liveWeather)); } else { res.writeHead(500, { 'Content-Type': 'text/plain' }); res.end('Failed to fetch weather data.'); } } else { res.writeHead(500, { 'Content-Type': 'text/plain' }); res.end('Failed to fetch IP location'); } } catch (error) { res.writeHead(500, { 'Content-Type': 'text/plain' }); res.end('Failed to fetch weather data.' + error); } 改为调用云函数 但上面的代码有个问题，那就是前端可以很方便的就看到我的Key，因为本博客是静态网页的，没有后端，所有数据在前端都可以看到，尤其是这种会访问其他地址的接口，不是很安全。所以我们需要一个类似后端的来封装以下我们调用的接口，因此我把目光放到了云函数上。找了下比较有名的云函数，发现华为云提供了每月100万次的免费请求额度，感觉还不错，所以本次就采用华为云函数来实现代码封装。 华为控制台中叫做函数工作流，点击创建函数后可以选择模板，我就使用了最简单的空白模板。 之后将代码粘贴一下就行了——我以为这样就可以了。但是我忽略了一点，此时访问高德接口的已经不是我们访问博客的ip了，而是云函数，所以就ip地址这里需要修改一下，获取到实际的客户端ip地址： const clientIp = req.headers['x-forwarded-for'] || req.connection.remoteAddress; 除此之外还需要修改下bootstrap中调用的node版本，改为18.15，因为这个版本已经内置了fetch，我们才能正常使用。 /opt/function/runtime/nodejs18.15/rtsp/nodejs/bin/node $RUNTIME_CODE_ROOT/index.js 这里是最终的index.js的完整代码: const http = require('http'); // Import Node.js core module var server = http.createServer(async function (req, res) { // Create web server if (req.url.startsWith(&quot;/weather&quot;)) { try { const clientIp = req.headers['x-forwarded-for'] || req.connection.remoteAddress; let ipUrl = 'https://restapi.amap.com/v3/ip?ip=' + clientIp + '&amp;key=&lt;我的Key&gt;'; const ipResponse = await fetch(ipUrl); if (!ipResponse.ok) { throw new Error('Failed to fetch IP location'); } const ipData = await ipResponse.json(); if (ipData.status === '1') { let adcode = ipData.adcode; let city = ipData.city; const addUrl = `https://restapi.amap.com/v3/config/district?keywords=${city}&amp;subdistrict=0&amp;key=&lt;我的Key&gt;`; const addResponse = await fetch(addUrl); if (!addResponse.ok) { throw new Error(`Network response was not ok: ${addResponse.status}`); } const addData = await addResponse.json(); // 检查districts是否为空 if (addData.districts.length &gt; 0) { // 获取第一个district的adcode adcode = addData.districts[0].adcode; } const weatherResponse = await fetch(`https://restapi.amap.com/v3/weather/weatherInfo?city=${adcode}&amp;key=&lt;我的Key&gt;`); if (!weatherResponse.ok) { throw new Error('Failed to fetch weather information.'); } const weatherData = await weatherResponse.json(); if (weatherData.status === '1' &amp;&amp; weatherData.lives.length &gt; 0) { const liveWeather = weatherData.lives[0]; res.writeHead(200, { 'Content-Type': 'application/json' }); res.end(JSON.stringify(liveWeather)); } else { res.writeHead(500, { 'Content-Type': 'text/plain' }); res.end('Failed to fetch weather data.'); } } else { res.writeHead(500, { 'Content-Type': 'text/plain' }); res.end('Failed to fetch IP location'); } } catch (error) { res.writeHead(500, { 'Content-Type': 'text/plain' }); res.end('Failed to fetch weather data.' + error); } } else { res.writeHead(404, { 'Content-Type': 'text/plain' }); res.end('Invalid Request!'); } }); server.listen(8000, '127.0.0.1'); // Listen for incoming requests on port 8000 改好后点击部署，然后记得添加触发器作为提供给外部的网关，最后封装的接口地址即为触发器的调用URL 添加组件 最后一步就是修改博客主题的模板了 1、在sidebar.ejs中新增一个显示天气的div &lt;!-- 新增天气模块 --&gt; &lt;div class=&quot;weather-info&quot;&gt; &lt;div class=&quot;weather-temperature&quot;&gt;&lt;/div&gt; &lt;div class=&quot;weather-details&quot;&gt; &lt;div class=&quot;weather-city&quot;&gt;&lt;/div&gt; &lt;div class=&quot;weather-condition&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; 2、在main.less中添加下样式，让其更好看一点 .weather-info { display: flex; align-items: center; .weather-temperature { flex: 1; font-size: 24px; } .weather-details { flex: 2; display: flex; flex-direction: column; justify-content: center; .weather-city { text-align: left; } .weather-condition { text-align: left; } } } 3、最后在scripts.ejs中添加更新天气数据和调用云函数接口的脚本 &lt;script&gt; // 更新天气数据 function updateWeatherInfo(city, weather, temperature) { // 使用获取到的数据更新DOM document.querySelector('.weather-city').textContent = `${city}`; document.querySelector('.weather-condition').textContent = `${weather}`; document.querySelector('.weather-temperature').textContent = `${temperature}°C`; } // 调用云函数接口 fetch('https://05d001686f8e43249d001efa0d32a2a3.apig.cn-south-1.huaweicloudapis.com/weather') .then(response =&gt; { // 检查响应状态是否成功 if (!response.ok) { throw new Error('Network response was not ok'); } // 将响应体转换为JSON格式 return response.json(); }) .then(data =&gt; { // 提取所需的数据并打印 const { city, weather, temperature } = data; updateWeatherInfo(city, weather, temperature); }) .catch(error =&gt; { // 打印错误信息 console.error('There has been a problem with your fetch operation:', error); }); &lt;/script&gt; 如此就大功告成啦！ ","link":"https://dove-gugugu.github.io/post/gridea-configuration/"},{"title":"Xtrabackup备份恢复","content":"记录通过innobackupex全备份、恢复mysql的过程 假定mysql数据库的配置文件为/etc/my.cnf ，数据文件存储路径为/db/data，root用户密码为123456，sock文件为/tmp/mysqld.sock，备份文件放在/data/backup/full/ 目录下 进行全备份： sudo innobackupex --user=root --password=123456 --no-timestamp /data/backup/full/ 这将在指定的目录/data/backup/full/中创建一个全备份。 如果MySQL服务正在运行，请确保停止MySQL服务： sudo systemctl stop mysql 清空数据目录： sudo rm -rf /db/data/* 注意：请提前备份好数据库数据以便在需要恢复时使用。 解压缩备份文件并恢复数据库： sudo innobackupex --user=root --password=123456 --apply-log /data/backup/full/ sudo innobackupex --user=root --password=123456 --copy-back /data/backup/full/ 这将解压缩备份文件并将数据文件复制回/db/data/目录。 修复文件权限： sudo chown -R mysql:mysql /db/data/ 这将确保MySQL用户对数据目录具有适当的权限。 启动MySQL服务： sudo systemctl start mysql MySQL服务将会使用备份数据文件启动。 检查MySQL服务状态： sudo systemctl status mysql 如果一切正常，MySQL应该成功恢复备份数据。 ","link":"https://dove-gugugu.github.io/post/xtrabackup-bei-fen-hui-fu/"},{"title":"@Resource","content":" @Resource 和 @Autowired 的区别 @Resource 的作用相当于@Autowired，只不过@Autowired 按 byType 自动注入 提供方不同 @Autowired 是 Spring 提供的，@Resource 是 J2EE 提供的 装配时默认类型不同 @Autowired 只按 type 装配,@Resource 默认是按 name 装配 @Autowired 默认按类型装配，默认情况下必须要求依赖对象存在，如果要允许null值，可以设置它的required属性为false。如果想使用名称装配可以结合@Qualifier注解进行使用 @Resource 默认按照名称装配，名称可以通过 name 属性进行指定，如果没有指定 name 属性，当注解写在字段上时，默认取字段名进行名称查找。如果注解写在 setter 方法上默认取属性名进行装配。当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配 什么时候用@Resource 使用 @Resource 可以消除 IDE 的 'Field injection is not recommended' 警告，多多少少是有点⚠洁癖在的 注意点 当有同一个接口被两个及以上类实现的时候，如果单单使用 @Resource 会出现希望单个Bean的匹配，却找到了多个的情况。 例如有一个水果接口 Fruit，同时有两个实现类：Apple、Banana 此时新建一个商店类Store注入Fruit接口 @Component public class Store { // 使用 @Resource 注入 @Resource private Fruit fruit; public void getFruit() { // 调用Furit接口中的售卖方法 fruit.sell(); } } 调用getFruit()方法后会出现NoUniqueBeanDefinitionException 异常 why 首先，当@Resource 中没有设置任何属性值时统统采用的是默认的值——默认按名称装配 按照 Spring Bean 的加载顺序，Store Bean 创建的时候，BeanFactory中已经创建了 Apple 和 Banana Bean 当 name 属性没有被设置时，就会执行下面的分支，根据是方法注入还是属性注入，分别设置为方法名称set后面的字符串或字段名称。 当指定 type 时 @Resource(type = Apple.class) 设置 type 属性后，isDefaultName 的值还是为 true，所以执行的还是 resolveDependency 方法。但是由于添加了类型的限制，所以也就不会匹配到多个 Bean，而产生异常。 既指定了name属性，又指定了type类型，但是是不同的类； @Resource(name = “banana”, type = Apple.class) name 属性被设置为 banana，isDefaultName 变为 false，执行 resolveBeanByName 方法。但是由于找不到对应 beanName 为 banana，但是类型又为 Apple.class 的 bean，还是会抛出异常 总结 当@Resource不设置任何值时，isDefaultName会为true，当对应字段名称的bean或者BeanDefinition已存在时会走byName的形式，否则走byType的形式； 只指定了type属性时，只有当对应的名称不存在对应的bean或BeanDefinition，才会通过byType找到唯一的一个类型匹配的bean； 只指定了name属性，会执行getBean方法，根据指定的name来获取bean； 既指定了name属性，又指定了type属性，会先根据那么查找对应的bean，然后进行type类型比较。 @Autowired 装配顺序 @Autowired和@Resource的区别是什么？ IDEA 警告 Field injection is not recommended ","link":"https://dove-gugugu.github.io/post/resource/"},{"title":"@Autowired出现警告原因及解决方法","content":" 警告出现的原因 使用 @Autowired 注解对字段进行依赖注入时会出现警告 大概意思： 不建议直接在字段上进行依赖注入。 Spring 开发团队建议：在 Java Bean 中永远使用构造方法进行依赖注入。对于必须的依赖，永远使用断言来确认。 所谓基于 field 的注入，就是在变量上使用 @Autowired 注解进行依赖注入。这是我们最熟悉的一种方式，同时，也正是 Spring 团队所不推荐的方式。它用起来就像这样： @Autowired private DependencyClass aDependency; 基于 field 的注入可能会有什么问题 基于 field 的注入，虽然不是绝对禁止使用，但是它可能会带来一些隐含的问题。比如，在这篇博客中，作者给出了这样的一个代码： @Autowired private User user; private String school; public UserAccountServiceImpl() { this.school = user.getSchool(); } 初看起来好像没有什么问题，User 类会被作为一个依赖被注入到当前类中，同时这个类的 school 属性将在初始化时通过 user.getSchool() 方法来获得值。但是，这个代码在运行时，却会抛出如下的异常： Exception in thread &quot;main&quot; org.springframework.beans.factory.BeanCreationException: Error creating bean with name '...' defined in file [....class]: Instantiation of bean failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [...]: Constructor threw exception; nested exception is java.lang.NullPointerException 即，在执行 UserAccountServiceImpl() 这个构造方法时出现了 NPE。 出现这个问题的原因是，Java 在初始化一个类时，是按照 静态变量或静态语句块 –&gt; 实例变量或初始化语句块 –&gt; 构造方法 -&gt; @Autowired 的顺序 1，那么显而易见，在执行这个类的构造方法时，user 对象尚未被注入，它的值还是 null，从而产生了 NPE。 可选的解决方案 基于构造方法的注入 可能会因为依赖过多而显得冗长，需要注意的是在 Spring 4.3 及以后的版本中，如果这个类只有一个构造方法，那么这个构造方法上面也可以不写 @Autowired 注解 基于 setter 方法的注入 建议用于注入非必须的依赖，同时在类中应该对这个依赖提供一个合理的默认值 在 Spring 4.3 及以后的版本中，setter 上面的 @Autowired 注解是可以不写的 使用 @Resource 注解替换 @Autowired 因为构造方法和 setter 方法没有基于 field 方便，所以还是会找别的方法，比如@Resurce 详见 @Resource ","link":"https://dove-gugugu.github.io/post/autowired/"},{"title":"Feign笔记","content":"Feign原理简述 启动时，程序会进行包扫描，扫描所有包下所有@FeignClient注解的类，并将这些类注入到spring的IOC容器中。当定义的Feign中的接口被调用时，通过JDK的动态代理来生成RequestTemplate。 RequestTemplate中包含请求的所有信息，如请求参数，请求URL等。 RequestTemplate生成Request，然后将Request交给client处理，这个client默认是JDK的HTTPUrlConnection，也可以是OKhttp、Apache的HTTPClient等。 最后client封装成LoadBaLanceClient，结合ribbon负载均衡地发起调用。 使用feign客户端 在服务消费者调用服务提供者时，底层通过HTTP Client 的方式访问 使用注解@EnableFeignClients 启用 feign客户端 @SpringBootApplication @EnableFeignClients public class TestApplication { public static void main(String[] args) { SpringApplication.run(TestApplication.class, args); } } 使用注解@FeignClient 定义feign客户端 该例子定义了一个feign客户端，将远程服务 http://test-service/test/echo 映射为一个本地Java方法调用。 @FeignClient(name = &quot;test-service&quot;, path = &quot;/test&quot;) public interface TestService { @RequestMapping(value = &quot;/echo&quot;, method = RequestMethod.GET) TestModel echo(@RequestParam(&quot;parameter&quot;) String parameter); } 使用注解@Autowired 使用上面所定义feign的客户端 @Autowired TestService testService; public void run() { // 这里的使用本地Java API的方式调用远程的Restful接口 TestModel dto = testService.echo(&quot;Hello,你好!&quot;); log.info(&quot;echo : {}&quot;, dto); } FeignClient注解的一些属性 属性名 默认值 作用 备注 value 空字符串 调用服务名称，和name属性相同 name 空字符串 调用服务名称，和value属性相同 url 空字符串 全路径地址或hostname，http或https可选 一般用于调试，可以手动指定@FeignClient调用的地址 path 空字符串 自动给所有方法的requestMapping前加上前缀，类似与controller类上的requestMapping decode404 false 配置响应状态码为404时是否应该抛出FeignExceptions configuration {} 自定义当前feign client的一些配置 参考FeignClientsConfiguration fallback void.class 熔断机制，调用失败时，走的一些回退方法，可以用来抛出异常或给出默认返回数据 底层依赖hystrix，启动类要加上@EnableHystrix ","link":"https://dove-gugugu.github.io/post/feign-bi-ji/"}]}